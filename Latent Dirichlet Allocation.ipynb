{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://blog.echen.me/2011/08/22/introduction-to-latent-dirichlet-allocation/\n",
    "\n",
    "> 1. Randomly assign a topic to a document\n",
    "> 2. Given the words assigned to the topic, calculate the probability of a topic to a document\n",
    "> 3. Given the words assigned to the topic, calculate the probability of a topic to a word\n",
    "> 4. Multiply step 2 * step 3, assign topic of document \n",
    "> 5. Iteratively repeated the process until the stopping conditions meet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I was wondering if anyone out there could enlighten me on this car I saw\\nthe other day. It was a 2-door sports car, looked to be from the late 60s/\\nearly 70s. It was called a Bricklin. The doors were really small. In addition,\\nthe front bumper was separate from the rest of the body. This is \\nall I know. If anyone can tellme a model name, engine specs, years\\nof production, where this car is made, history, or whatever info you\\nhave on this funky looking car, please e-mail.']\n"
     ]
    }
   ],
   "source": [
    "data = fetch_20newsgroups(remove=(\"headers\", \"footers\", \"quotes\"))\n",
    "\n",
    "print(data.data[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 1000\n",
    "\n",
    "tf_vectorizer = CountVectorizer(max_features=max_features,\n",
    "                               stop_words=\"english\")\n",
    "\n",
    "tf = tf_vectorizer.fit_transform(data.data)\n",
    "\n",
    "vocab = tf_vectorizer.get_feature_names()\n",
    "\n",
    "n_top_words = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(n_components=20)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_topics = 20\n",
    "\n",
    "model = LatentDirichletAllocation(n_components= n_topics)\n",
    "\n",
    "model.fit(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.00000001e-02 5.00000006e-02 5.00000002e-02 ... 2.17500011e+00\n",
      "  5.00000004e-02 1.40296817e+00]\n",
      " [2.25452642e+01 5.00000002e-02 5.00000032e-02 ... 5.00000007e-02\n",
      "  5.00000001e-02 5.00000007e-02]\n",
      " [5.00000007e-02 4.05023749e+01 5.00000002e-02 ... 1.47943049e+02\n",
      "  7.12233171e+00 1.61249399e+02]\n",
      " ...\n",
      " [5.00000000e-02 1.20611072e+01 5.00000000e-02 ... 1.14021803e+01\n",
      "  5.00000004e-02 1.71087567e+01]\n",
      " [5.00000005e-02 5.00000006e-02 5.00000002e-02 ... 2.57273392e-01\n",
      "  5.00000005e-02 5.00000108e-02]\n",
      " [5.00000004e-02 5.00000007e-02 5.00000023e-02 ... 4.57986394e+01\n",
      "  4.81710775e+00 1.16020976e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(model.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00208333 0.00208333 0.00208333 ... 0.00208333 0.00208333 0.00208333]\n",
      " [0.0025     0.0025     0.0025     ... 0.0025     0.0025     0.0025    ]\n",
      " [0.00060241 0.00060241 0.00060241 ... 0.00060241 0.00060241 0.00060241]\n",
      " ...\n",
      " [0.11039019 0.00454545 0.00454545 ... 0.00454545 0.00454545 0.00454545]\n",
      " [0.00294118 0.00294118 0.00294118 ... 0.00294118 0.00294118 0.00294118]\n",
      " [0.00357143 0.12888659 0.00357143 ... 0.00357143 0.00357143 0.00357143]]\n"
     ]
    }
   ],
   "source": [
    "print(model.transform(tf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_words = {}\n",
    "\n",
    "for topic, comp in enumerate(model.components_):\n",
    "    # for the n-dimensional array \"arr\":\n",
    "    # argsort() returns a ranked n-dimensional array of arr, call it \"ranked_array\"\n",
    "    # which contains the indices that would sort arr in a descending fashion\n",
    "    # for the ith element in ranked_array, ranked_array[i] represents the index of the\n",
    "    # element in arr that should be at the ith index in ranked_array\n",
    "    # ex. arr = [3,7,1,0,3,6]\n",
    "    # np.argsort(arr) -> [3, 2, 0, 4, 5, 1]\n",
    "    # word_idx contains the indices in \"topic\" of the top num_top_words most relevant\n",
    "    # to a given topic ... it is sorted ascending to begin with and then reversed (desc. now)    \n",
    "    # word_idx = np.argsort(comp)[::-1][:9]\n",
    "    \n",
    "    word_idx = comp.argsort()[-6:]\n",
    "    # store the words most relevant to the topic\n",
    "    topic_words[topic] = [vocab[i] for i in word_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: ['current', 'ground', 'used', 'use', 'bike', 'power'],\n",
       " 1: ['section', 'bit', 'program', 'entry', 'output', 'file'],\n",
       " 2: ['just', 'going', 'don', 'know', 'said', 'people'],\n",
       " 3: ['guns', 'people', 'state', 'law', 'government', 'gun'],\n",
       " 4: ['nasa', 'launch', 'armenians', 'turkish', 'armenian', 'space'],\n",
       " 5: ['pl', 'a86', 'b8f', 'g9v', 'max', 'ax'],\n",
       " 6: ['edu', 'ftp', 'software', 'version', 'image', 'available'],\n",
       " 7: ['db', 'jesus', 'believe', 'does', 'people', 'god'],\n",
       " 8: ['points', 'period', 'team', 'games', 'play', 'game'],\n",
       " 9: ['use', 'know', 've', 'don', 'just', 'like'],\n",
       " 10: ['like', 'good', 'year', 'just', 'don', 'think'],\n",
       " 11: ['looking', 'help', 'mail', 'does', 'know', 'thanks'],\n",
       " 12: ['memory', 'use', 'window', 'using', 'problem', 'windows'],\n",
       " 13: ['just', 'read', 'question', 'book', 'years', 'time'],\n",
       " 14: ['000', 'april', 'san', '1993', 'university', 'new'],\n",
       " 15: ['new', '20', '10', 'sale', '50', '00'],\n",
       " 16: ['11', 'scsi', '25', '10', '16', 'drive'],\n",
       " 17: ['jesus', 'law', 'jewish', 'israeli', 'jews', 'israel'],\n",
       " 18: ['public', 'clipper', 'keys', 'encryption', 'chip', 'key'],\n",
       " 19: ['email', 'send', 'internet', 'mail', 'com', 'edu']}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic0</th>\n",
       "      <th>Topic1</th>\n",
       "      <th>Topic2</th>\n",
       "      <th>Topic3</th>\n",
       "      <th>Topic4</th>\n",
       "      <th>Topic5</th>\n",
       "      <th>Topic6</th>\n",
       "      <th>Topic7</th>\n",
       "      <th>Topic8</th>\n",
       "      <th>Topic9</th>\n",
       "      <th>Topic10</th>\n",
       "      <th>Topic11</th>\n",
       "      <th>Topic12</th>\n",
       "      <th>Topic13</th>\n",
       "      <th>Topic14</th>\n",
       "      <th>Topic15</th>\n",
       "      <th>Topic16</th>\n",
       "      <th>Topic17</th>\n",
       "      <th>Topic18</th>\n",
       "      <th>Topic19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Doc0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc3</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Topic0  Topic1  Topic2  Topic3  Topic4  Topic5  Topic6  Topic7  Topic8  \\\n",
       "Doc0    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00   \n",
       "Doc1    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00   \n",
       "Doc2    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00   \n",
       "Doc3    0.01    0.01    0.01    0.01    0.01    0.01    0.01    0.01    0.01   \n",
       "Doc4    0.00    0.00    0.00    0.00    0.09    0.00    0.27    0.00    0.00   \n",
       "\n",
       "      Topic9  Topic10  Topic11  Topic12  Topic13  Topic14  Topic15  Topic16  \\\n",
       "Doc0    0.38     0.00     0.16     0.00     0.43     0.00     0.00     0.00   \n",
       "Doc1    0.22     0.00     0.41     0.00     0.18     0.00     0.00     0.15   \n",
       "Doc2    0.52     0.05     0.29     0.13     0.00     0.00     0.00     0.00   \n",
       "Doc3    0.01     0.01     0.01     0.01     0.01     0.01     0.01     0.01   \n",
       "Doc4    0.00     0.47     0.00     0.00     0.00     0.00     0.00     0.00   \n",
       "\n",
       "      Topic17  Topic18  Topic19  \n",
       "Doc0     0.00     0.00     0.00  \n",
       "Doc1     0.00     0.00     0.00  \n",
       "Doc2     0.00     0.00     0.00  \n",
       "Doc3     0.01     0.63     0.24  \n",
       "Doc4     0.00     0.00     0.13  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics =  model.transform(tf)\n",
    "\n",
    "topicnames = [\"Topic\" + str(i) for i in range(model.n_components)]\n",
    "\n",
    "docnames = [\"Doc\" + str(i) for i in range(len(data.data))]\n",
    "\n",
    "df_topic = pd.DataFrame(np.round(topics, 2), columns=topicnames, index=docnames)\n",
    "\n",
    "df_topic.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
